{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dde6b06",
   "metadata": {},
   "source": [
    "# Collaborative filtering based on interactions dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090557cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b52664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to display all columns\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option(\"display.max_seq_items\")\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2059f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import user interactions\n",
    "interaction_chunks = pd.read_csv(\"../raw_data/goodreads_interactions.csv\", chunksize=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7722cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 228648343 ../raw_data/goodreads_interactions.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../raw_data/goodreads_interactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c98c464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in interaction: 228648343\n",
      "Interactions dataset explored: 1400000 rows\n",
      "unique books explored: 374975\n",
      "Books from interactions found in book titles: 121782\n",
      "As percent: 32.47736515767718\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows in interaction: 228648343\",\n",
    "      f\"Interactions dataset explored: {200000*7} rows\",\n",
    "      f\"unique books explored: 374975\",\n",
    "      f\"Books from interactions found in book titles: 121782\",\n",
    "      f\"As percent: {(121782/374975) * 100}\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57ff41",
   "metadata": {},
   "source": [
    "## Define functions to downcast data and get score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fec99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcasting columns\n",
    "def downcast(df):\n",
    "    int_8_cols = [\"is_read\", \"rating\", \"is_reviewed\"]\n",
    "    df[int_8_cols] = df[int_8_cols].astype(\"int8\")\n",
    "    df[[\"user_id\", \"book_id\"]] = df[[\"user_id\", \"book_id\"]].astype(\"int32\")\n",
    "    return df\n",
    "\n",
    "# get score\n",
    "def get_score(interactions_df): #TODO: think of how to include rating in score\n",
    "    return interactions_df[\"is_read\"] \\\n",
    "           + interactions_df[\"rating\"] \\\n",
    "           + interactions_df[\"is_reviewed\"] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a142a",
   "metadata": {},
   "source": [
    "## Test functions on one chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6fed079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12171</th>\n",
       "      <td>14</td>\n",
       "      <td>10205</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39148</th>\n",
       "      <td>91</td>\n",
       "      <td>26113</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43369</th>\n",
       "      <td>104</td>\n",
       "      <td>28389</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  book_id  is_read  rating  is_reviewed\n",
       "12171       14    10205        1       4            1\n",
       "39148       91    26113        1       4            0\n",
       "43369      104    28389        1       2            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   user_id      50000 non-null  int64\n",
      " 1   book_id      50000 non-null  int64\n",
      " 2   is_read      50000 non-null  int64\n",
      " 3   rating       50000 non-null  int64\n",
      " 4   is_reviewed  50000 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 1.9 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do int32 values retain full info? Let's check: \n",
      "\n",
      "user_id: yes\n",
      "book_id: yes\n",
      "is_read: yes\n",
      "rating: yes\n",
      "is_reviewed: yes\n",
      "\n",
      "What about int8?\n",
      "\n",
      "user_id: yes\n",
      "book_id: no\n",
      "is_read: yes\n",
      "rating: yes\n",
      "is_reviewed: yes\n",
      "\n",
      "Memory usage after downcasting\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   user_id      50000 non-null  int32\n",
      " 1   book_id      50000 non-null  int32\n",
      " 2   is_read      50000 non-null  int8 \n",
      " 3   rating       50000 non-null  int8 \n",
      " 4   is_reviewed  50000 non-null  int8 \n",
      "dtypes: int32(2), int8(3)\n",
      "memory usage: 537.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See the first chunk to get a sense of data\n",
    "first_chunk = next(interaction_chunks)\n",
    "print(\"Samples\")\n",
    "display(first_chunk.sample(3))\n",
    "\n",
    "print(\"Info\")\n",
    "display(first_chunk.info())\n",
    "\n",
    "# Processing interactions data\n",
    "first_chunk.dtypes\n",
    "print(\"Do int32 values retain full info? Let's check:\", \"\\n\")\n",
    "for col in first_chunk.columns:\n",
    "    test = (first_chunk[col].astype(\"int32\") == first_chunk[col]).all()\n",
    "    print(f\"{col}: {'yes' if test else 'no'}\")\n",
    "\n",
    "print(\"\\nWhat about int8?\\n\")\n",
    "for col in first_chunk.columns:\n",
    "    test = (first_chunk[col].astype(\"int8\") == first_chunk[col]).all()\n",
    "    print(f\"{col}: {'yes' if test else 'no'}\")\n",
    "\n",
    "print(\"\\nMemory usage after downcasting\")\n",
    "downcast(first_chunk)\n",
    "display(first_chunk.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distribution for is_read, rating, and i_reviewed\n",
    "first_chunk.sample(5)\n",
    "first_chunk[[\"is_read\", \"rating\", \"is_reviewed\"]].plot(kind=\"hist\", subplots=True, xticks=[0, 1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score\n",
    "first_chunk[\"score\"] = get_score(first_chunk)\n",
    "first_chunk.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c65c2",
   "metadata": {},
   "source": [
    "## Process in chunks to get CSR matrix of scores for 1_400_000 user-item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build stable ID maps... chatgpt recommended\n",
    "user_ids = set()\n",
    "book_ids = set()\n",
    "\n",
    "start = time.time()\n",
    "for chunk in pd.read_csv(\"../raw_data/goodreads_interactions.csv\", chunksize=200_000):\n",
    "    chunk = downcast(chunk)\n",
    "\n",
    "    user_ids.update(chunk[\"user_id\"].unique().tolist())\n",
    "    book_ids.update(chunk[\"book_id\"].unique().tolist())\n",
    "\n",
    "# Stable 0-based mappings...\n",
    "user_ids = list(user_ids)\n",
    "book_ids = list(book_ids)\n",
    "\n",
    "user_map = {u: i for i, u in enumerate(user_ids)}\n",
    "book_map = {b: i for i, b in enumerate(book_ids)}\n",
    "\n",
    "print(f\"No. of users: {len(user_map)}\", f\"No. of books: {len(book_map)}\", sep=\"\\n\")\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(f\"Time taken: {duration}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3c13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6 chunks\n",
      "Time taken: 0.24044299125671387\n"
     ]
    }
   ],
   "source": [
    "# Getting arrays for users, items, and scores\n",
    "from IPython.display import clear_output\n",
    "user_list = []\n",
    "book_list = []\n",
    "score_list = []\n",
    "\n",
    "start = time.time()\n",
    "for chunk_no, chunk in enumerate(pd.read_csv(\"../raw_data/goodreads_interactions.csv\", chunksize=200_000)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processed {chunk_no} chunks\")\n",
    "    chunk = downcast(chunk)\n",
    "    scores = get_score(chunk)\n",
    "\n",
    "    # Map to 0-based index\n",
    "    u_idx = chunk[\"user_id\"]    # Trying without mapping .map(user_map)\n",
    "    b_idx = chunk[\"book_id\"]    # .map(book_map)\n",
    "\n",
    "    # drop NaN\n",
    "    mask = u_idx.notna() & b_idx.notna()\n",
    "    u_idx = u_idx[mask]\n",
    "    b_idx = b_idx[mask]\n",
    "    scores = scores[mask]\n",
    "\n",
    "    user_list.append(u_idx.to_numpy())\n",
    "    book_list.append(b_idx.to_numpy())\n",
    "    score_list.append(scores.to_numpy())\n",
    "    # Last chunk to be processes is currently: 5\n",
    "    if chunk_no > 5:\n",
    "        break\n",
    "end = time.time()\n",
    "# Make 1D arrays:\n",
    "user_idx = np.concatenate(user_list)\n",
    "book_idx = np.concatenate(book_list)\n",
    "scores   = np.concatenate(score_list)\n",
    "\n",
    "duration = end - start\n",
    "print(f\"Time taken: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2748f382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374975"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_book_extracted = np.unique_counts(book_idx)[1].shape[0]\n",
    "no_book_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cac3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix of scores. Rows are users and columns are books\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "matrix = csr_matrix(\n",
    "    (scores, (user_idx, book_idx)),\n",
    "    dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488be732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all user-book pairs exist in the chunk. Check chunk by loc\n",
    "# Index is between 1200000 and 1400000\n",
    "\n",
    "i_loc = 1400000 - 2008\n",
    "user = chunk.loc[i_loc, [\"user_id\"]].values\n",
    "book = chunk.loc[i_loc, [\"book_id\"]].values\n",
    "print(f\"User no {user} for book no {book}\")\n",
    "display(chunk.loc[i_loc])\n",
    "\n",
    "print(f\"Score for user {user} for book no {book} is:\")\n",
    "display(get_score(chunk.loc[i_loc]))\n",
    "\n",
    "print(\"Checking whether matrix score corresponds to this...\")\n",
    "matrix[user, book]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4f632",
   "metadata": {},
   "source": [
    "# Test a first model using Implicit library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fadfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krahmed96/.pyenv/versions/3.12.9/envs/the_book_thrift/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fcdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_full = matrix.tocsr()\n",
    "n_users, n_items = user_items_full.shape\n",
    "\n",
    "# build train as a copy\n",
    "user_items_train = user_items_full.copy().tocsr()\n",
    "\n",
    "# for each user, hold out 1 interacted item (if they have any)\n",
    "test_items = {}  # user_id -> set of held-out item_ids\n",
    "\n",
    "for u in range(n_users):\n",
    "    start, end = user_items_full.indptr[u], user_items_full.indptr[u+1]\n",
    "    items = user_items_full.indices[start:end]\n",
    "\n",
    "    if len(items) == 0:\n",
    "        continue\n",
    "\n",
    "    held_out = np.random.choice(items, size=1, replace=False)\n",
    "    test_items[u] = set(held_out)\n",
    "\n",
    "    # remove held-out interactions from the train matrix\n",
    "    for i in held_out:\n",
    "        user_items_train[u, i] = 0\n",
    "\n",
    "user_items_train.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2fccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:12<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = AlternatingLeastSquares(\n",
    "    factors = 128,\n",
    "    regularization=0.1,\n",
    "    iterations=30\n",
    ")\n",
    "model.fit(user_items_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging error below\n",
    "# print(\"mat shape:\", matrix.shape[0])                     # should be (num_users, num_items)\n",
    "# print(\"user_factors shape:\", model.user_factors.shape)  # (num_users, n_factors)\n",
    "print(f\"Shape of model.user_factors : {model.user_factors.shape[0]}\")\n",
    "print(f\"Shape of model.item_factors: {model.item_factors.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bc9ddb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1494, 1210, 1211], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some recommendations\n",
    "user = 500\n",
    "top_3_recs = model.recommend(userid=user, user_items=matrix[user], N=10)[0][:3]\n",
    "top_3_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2638117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match using book titles dataset\n",
    "book_titles = pd.read_csv(\"../raw_data/book_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b88c54ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 374975 books extracted from interactions, only \n",
      "121782 could be found in book titles df. 32.47736515767718%\n"
     ]
    }
   ],
   "source": [
    "# display(book_titles[book_titles[\"book_id\"].isin(top_3_recs)])\n",
    "book_titles[\"book_id\"] = book_titles[\"book_id\"].astype(\"int32\")\n",
    "book_titles[book_titles[\"book_id\"].isin(book_idx.tolist())].shape\n",
    "print(f\"Out of 374975 books extracted from interactions, only \\n121782 could be found in book titles df. {121782/374975 * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check user and the books they've rated\n",
    "interactions = pd.read_csv(\"../raw_data/goodreads_interactions.csv\",\n",
    "                           nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fa7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[(interactions[\"user_id\"] == user) &\n",
    "             (interactions[\"is_read\"] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03bedf",
   "metadata": {},
   "source": [
    "## Creating test set to test recommendations using chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74267704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_items_full = user_items.tocsr()\n",
    "n_users, n_items = user_items_full.shape\n",
    "\n",
    "# build train as a copy\n",
    "user_items_train = user_items_full.copy().tocsr()\n",
    "\n",
    "# for each user, hold out 1 interacted item (if they have any)\n",
    "test_items = {}  # user_id -> set of held-out item_ids\n",
    "\n",
    "for u in range(n_users):\n",
    "    start, end = user_items_full.indptr[u], user_items_full.indptr[u+1]\n",
    "    items = user_items_full.indices[start:end]\n",
    "\n",
    "    if len(items) == 0:\n",
    "        continue\n",
    "\n",
    "    held_out = np.random.choice(items, size=1, replace=False)\n",
    "    test_items[u] = set(held_out)\n",
    "\n",
    "    # remove held-out interactions from the train matrix\n",
    "    for i in held_out:\n",
    "        user_items_train[u, i] = 0\n",
    "\n",
    "user_items_train.eliminate_zeros()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "hits = 0\n",
    "total = 0\n",
    "\n",
    "for u, positives in test_items.items():\n",
    "    if not positives:\n",
    "        continue\n",
    "\n",
    "    # get recommendations for this user from the TRAIN matrix\n",
    "    rec_ids, _ = model.recommend(\n",
    "        u,\n",
    "        user_items_train[u],\n",
    "        N=K\n",
    "    )\n",
    "\n",
    "    rec_set = set(rec_ids)\n",
    "    # count how many test positives appear in top-K\n",
    "    hits += len(positives & rec_set)\n",
    "    total += len(positives)\n",
    "\n",
    "recall_at_k = hits / total if total > 0 else 0.0\n",
    "print(\"Recall@{} = {:.4f}\".format(K, recall_at_k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768317d0",
   "metadata": {},
   "source": [
    "# Books dataset exploration\n",
    "All columns are object type, so number ones need to be converted. <br>\n",
    "We may select languages that are eng or '' (as those are Eng too, it seems) <br>\n",
    "We may want to make individual columns for popular shelves (such as 'to-read count') <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k = pd.read_json(\"../raw_data/goodreads_books.json.gz\",\n",
    "                         lines=True,\n",
    "                         compression=\"gzip\",\n",
    "                         nrows=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6547aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option(\"display.max_seq_items\")\n",
    "pd.reset_option(\"display.max_colwidth\")\n",
    "\n",
    "cols_to_keep = [\n",
    "    \"text_reviews_count\",\n",
    "    \"language_code\",\n",
    "    \"popular_shelves\",\n",
    "    \"average_rating\",\n",
    "    \"description\",\n",
    "    \"authors\",\n",
    "    \"num_pages\",\n",
    "    \"publication_year\",\n",
    "    \"ratings_count\",\n",
    "    \"book_id\",\n",
    "    \"work_id\"\n",
    "]\n",
    "books_50k = books_50k[cols_to_keep]\n",
    "books_50k.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genres\n",
    "print(\"Genres Dataset Columns\")\n",
    "print(genres.columns, \"\\n\")\n",
    "\n",
    "print(\"Size of dataset\", genres.shape[0])\n",
    "print(\"Dataset dtypes\", \"\\n\", genres.dtypes)\n",
    "\n",
    "# Null values\n",
    "# Map empty dicts to null\n",
    "genres[\"genres\"] = genres[\"genres\"].map(\n",
    "    lambda s: s if len(s) > 0 else pd.NA\n",
    ")\n",
    "print(\"\\n\", \"Null values in genres\")\n",
    "print(genres.isnull().sum())\n",
    "genres.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 3 genres for every book\n",
    "def get_top_genres(genre_dict):\n",
    "    if isinstance(genre_dict, dict):\n",
    "        print((max(genre_dict, key = genre_dict.get)))\n",
    "get_top_genres({'fantasy': 10, 'fiction': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb929a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Books Dataset\")\n",
    "print(books_50k.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dtypes\n",
    "num_cols = ['text_reviews_count',\n",
    "            'average_rating',\n",
    "            'num_pages',\n",
    "            'ratings_count']\n",
    "\n",
    "# num_pages has several blank values. First check if any values other than digits\n",
    "books_50k.loc[:, num_cols] = books_50k[num_cols].replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "\n",
    "books_50k.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dtypes\n",
    "for col in num_cols:\n",
    "    books_50k.loc[:, col] = pd.to_numeric(books_50k[col], errors='coerce')\n",
    "\n",
    "books_50k.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_50k[num_cols].plot(subplots=True, kind='hist', figsize=(8, 10))\n",
    "books_50k[num_cols].plot(kind='box', subplots=True, figsize=(12, 6))\n",
    "# Removing max from text_reviews_count and keeping num_pages below 2000\n",
    "books_50k = books_50k[\n",
    "    (books_50k['text_reviews_count'] < 38878.000000) &\n",
    "    (books_50k['num_pages'] < 2000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))\n",
    "ax1.hist(books_50k['text_reviews_count'], bins=50, log=True)\n",
    "ax2.hist(books_50k['average_rating'])\n",
    "ax3.hist(books_50k['num_pages'], bins=50)\n",
    "ax4.hist(books_50k['ratings_count'], bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f43c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(li):\n",
    "    authors = []\n",
    "    for author_dict in li:\n",
    "        authors.append(\n",
    "            author_dict['author_id']\n",
    "        )\n",
    "\n",
    "    return authors\n",
    "\n",
    "books_50k[\"extractd_authors\"] = books_50k[\"authors\"].apply(\n",
    "    extract_authors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_popular_shelves(li):\n",
    "    popularity_threshold = 500\n",
    "    shelves = []\n",
    "    for d in li:\n",
    "        if int(d[\"count\"]) > popularity_threshold:\n",
    "            shelves.append({d[\"name\"]: d[\"count\"]})\n",
    "    return shelves\n",
    "\n",
    "popular_shelves = books_50k[\"popular_shelves\"].apply(extract_popular_shelves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cf6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_shelves = Counter()\n",
    "\n",
    "for book_shelves in popular_shelves:\n",
    "    for shelf in book_shelves:\n",
    "        shelf_name = list(shelf.keys())[0]\n",
    "        all_shelves.update([shelf_name])\n",
    "\n",
    "all_shelves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e45a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining categorical columns\n",
    "cat_cols = ['country_code', 'language_code']\n",
    "pd.DataFrame(books_50k[cat_cols].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2437388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check language column\n",
    "# Show count for all languages\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(books_50k['language_code'].value_counts().sort_values())\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "# keep only eng lang books\n",
    "eng_lang = ['eng', 'en-US', 'en-GB', 'en-CA', '']\n",
    "books_50k = books_50k[books_50k['language_code'].isin(eng_lang)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a57f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similar books column\n",
    "books_50k.similar_books.apply(lambda x: len(x)).sort_values()\n",
    "\n",
    "# check num pages column\n",
    "books_50k.num_pages.value_counts().sort_index()\n",
    "display(books_50k['num_pages'].quantile([0.25, 0.5, 0.75, 0.9, 0.99, 1]))\n",
    "\n",
    "# remove the massive book as outlier\n",
    "books_50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# describe\n",
    "books_50k[num_cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max values for num cols\n",
    "books_50k[books_50k['num_pages'] == 945077.000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2, figsize=(10,6))\n",
    "# ax[0, 0].hist(books_50k['num_pages'], bins=20)\n",
    "# ax[0, 0].set_xlim(0, 2000)\n",
    "num_cols\n",
    "books_50k.num_pages.plot(kind='hist', xlim=(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976929e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k['num_pages'].quantile([0.5, 0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff2fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b07944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dummy model, keep only some columns\n",
    "books_50k.columns.tolist()\n",
    "books_50k_small = books_50k[['isbn',\n",
    "                             'text_reviews_count',\n",
    "                             'average_rating',\n",
    "                             'publication_year',\n",
    "                             'ratings_count']]  # No num pages as it has many missing.\n",
    "\n",
    "books_50k_small.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_50k_small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_book_thrift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
